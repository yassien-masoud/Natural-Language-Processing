{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy\n",
    "#!pip install ibm_watson\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import tweepy as tw\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='fake_tweets_id.jsonl'\n",
    "df =pd.read_json(open(filename,\"r\", encoding='utf8'),lines=True,orient= 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_list = [obj['id'] for obj in df['user']]  \n",
    "df_user_id_list = pd.DataFrame(user_id_list).drop_duplicates().reset_index(drop=True)[0].values.tolist()\n",
    "df_user_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the module \n",
    "import tweepy \n",
    "import json\n",
    "\n",
    "# assign the values accordingly \n",
    "consumer_key = \"put consumer_key \"\n",
    "consumer_secret = \"consumer_secret\"\n",
    "access_key = \"access_key\"\n",
    "access_secret = \"access_secret\"\n",
    "\n",
    "\n",
    "# authorization of consumer key and consumer secret \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "\n",
    "# set access to user's access key and access secret \n",
    "auth.set_access_token(access_key, access_secret) \n",
    "\n",
    "# calling the api \n",
    "api = tweepy.API(auth) \n",
    "\n",
    "\n",
    "# generating the tweets\n",
    "\n",
    "def tweets_of_user_ids(user_list_id):\n",
    "    user_tweets = {}\n",
    "    notvalid=[]\n",
    "    for id_num in user_list_id:\n",
    "        user_id = id_num\n",
    "        try:\n",
    "            user_tweets[id_num] = api.user_timeline(user_id)\n",
    "        except:\n",
    "            #print \"NotOk :\",row.id\n",
    "            notvalid.append(user_id)\n",
    "            #print x, \"added to valid\"\n",
    "        \n",
    "\n",
    "    users_dict_tweets = {}\n",
    "    for user_id, statuse in user_tweets.items():\n",
    "        users_dict_tweets[user_id] = []\n",
    "        for tweet in statuse:\n",
    "           users_dict_tweets[user_id].append(tweet.text) \n",
    "    print(notvalid)\n",
    "    return users_dict_tweets\n",
    "\n",
    "tweets = tweets_of_user_ids(df_user_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning \n",
    "def str_clean(tweets_list):\n",
    "    tweets = []\n",
    "    for text in tweets_list:\n",
    "        text = text.lower()\n",
    "        pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        text = pattern.sub('', text)\n",
    "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "        text = re.sub(r'rt' , '', text)\n",
    "        # tokenizing the text\n",
    "        tokens = word_tokenize(text)\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stop_words.discard(\"not\")\n",
    "        PS = PorterStemmer()\n",
    "        # words = [w for w in words if not w in stop_words]\n",
    "        #words = [PS.stem(w) for w in words if not w in stop_words]\n",
    "        words = ' '.join(words)\n",
    "        #print(words)\n",
    "        tweets.append(words)\n",
    "    return tweets\n",
    "            \n",
    "# Extracting tweets from the users dictionary\n",
    "def extract_tweet(dic):\n",
    "    clean_tweets={}\n",
    "    for user_id, tweets_list in dic.items():\n",
    "        clean_tweets[user_id]= str_clean(tweets_list)\n",
    "    return clean_tweets\n",
    "\n",
    "# Word counter\n",
    "def word_counter(dic):\n",
    "    tokenized_tweets = {}\n",
    "    for user_id, tweets_list in dic.items():\n",
    "        lis = []\n",
    "        for tweet in tweets_list:\n",
    "            lis.extend(word_tokenize(tweet))\n",
    "        word_count = FreqDist(lis)\n",
    "        tokenized_tweets[user_id] = word_count\n",
    "    return tokenized_tweets\n",
    "\n",
    "# Word counter without the stopwords \n",
    "def word_counter_stop_w(dic):\n",
    "    st_w = stopwords.words('english')\n",
    "    tokenized_tweets = {}\n",
    "    for user_id, tweets_list in dic.items():\n",
    "        lis = []\n",
    "        for tweet in tweets_list:\n",
    "            lis.extend(word_tokenize(tweet))\n",
    "        # remove stopwords\n",
    "        lis_stop_w = [word for word in lis if word not in st_w]\n",
    "        word_count = FreqDist(lis_stop_w)\n",
    "        tokenized_tweets[user_id] = word_count\n",
    "    return tokenized_tweets\n",
    "\n",
    "# Post_tag the tweets\n",
    "def pos_tag_tweets(dic):\n",
    "    pos_tag_dic = {}\n",
    "    chunk_grammar = \"NP: {<JJ><NN>}\"\n",
    "    chunk_parser = RegexpParser(chunk_grammar) \n",
    "    for user_id, tweets in dic.items():\n",
    "        tweet_list = []\n",
    "        for tweet in tweets:\n",
    "            tweet_tokenized = word_tokenize(tweet)\n",
    "            #print(tweet_tokenized)\n",
    "            tweet_pos_tag = pos_tag(tweet_tokenized)\n",
    "            #print(tweet_pos_tag)\n",
    "            [('Now', 'RB'), ('im', 'VBZ'), ('up', 'RP'), ('watch', 'JJ'), ('60', 'CD'), ('days', 'NNS'), ('in', 'IN')]\n",
    "            tweet_parser = [tag[0] for tag in tweet_pos_tag if tag[1]=='JJ']\n",
    "            #print(tweet_parser)\n",
    "            #tweet_list.append(chunk_parser.parse(tweet_parser))\n",
    "            tweet_list.append(tweet_parser)\n",
    "        pos_tag_dic[user_id] = tweet_list\n",
    "    return pos_tag_dic\n",
    "\n",
    "extr_tweets = extract_tweet(tweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_to_string(dicto):\n",
    "    dic={}\n",
    "    for user_id, string_list in dicto.items():\n",
    "        dic[user_id]= ' '.join(string_list)\n",
    "    return dic\n",
    "extr_tweets_strings = tweets_to_string(extr_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(extr_tweets_strings, orient='index', columns=['tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>429437147</th>\n",
       "      <td>and you ve got soo much more to achieve this i...</td>\n",
       "      <td>(0.12499999999999997, 0.4091666666666667)</td>\n",
       "      <td>(0.12499999999999997, 0.4091666666666667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507252116</th>\n",
       "      <td>happy bihday superstar rajinikanth hbdsupersta...</td>\n",
       "      <td>(0.43783068783068785, 0.7134920634920634)</td>\n",
       "      <td>(0.43783068783068785, 0.7134920634920634)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065961267440033794</th>\n",
       "      <td>good what are you grateful for today existing ...</td>\n",
       "      <td>(0.3385974025974026, 0.5524675324675324)</td>\n",
       "      <td>(0.3385974025974026, 0.5524675324675324)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750251127673729024</th>\n",
       "      <td>every man and woman on this eah is born to lea...</td>\n",
       "      <td>(0.2408936588103255, 0.5157435465768798)</td>\n",
       "      <td>(0.2408936588103255, 0.5157435465768798)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482175176</th>\n",
       "      <td>govmurphy woohoo omg i love this so much egolb...</td>\n",
       "      <td>(0.1299107142857143, 0.4399496336996337)</td>\n",
       "      <td>(0.1299107142857143, 0.4399496336996337)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120598108482736128</th>\n",
       "      <td>saluting the warrior spirit of cancer esconpro...</td>\n",
       "      <td>(0.17820634920634923, 0.4993174603174603)</td>\n",
       "      <td>(0.17820634920634923, 0.4993174603174603)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15611093</th>\n",
       "      <td>adamsinger until you live there and realize th...</td>\n",
       "      <td>(0.11846193022663612, 0.5541889483065954)</td>\n",
       "      <td>(0.11846193022663612, 0.5541889483065954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402622605</th>\n",
       "      <td>ଏକ ବୟସ ସମୟ ଏକ ବୟସ ସମୟ ଏକ ଆଇନ କ ଣ କଣ ଏକ ଆଇନ କ ଣ...</td>\n",
       "      <td>(0.8, 0.75)</td>\n",
       "      <td>(0.8, 0.75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243862687198654466</th>\n",
       "      <td>rudogumbo got you sis pmarkhansen yktv rudogum...</td>\n",
       "      <td>(0.39112554112554115, 0.47886904761904764)</td>\n",
       "      <td>(0.39112554112554115, 0.47886904761904764)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854734842</th>\n",
       "      <td>world energy conservation day december if you ...</td>\n",
       "      <td>(0.21497425997425998, 0.5580952380952381)</td>\n",
       "      <td>(0.21497425997425998, 0.5580952380952381)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 tweet  \\\n",
       "429437147            and you ve got soo much more to achieve this i...   \n",
       "507252116            happy bihday superstar rajinikanth hbdsupersta...   \n",
       "1065961267440033794  good what are you grateful for today existing ...   \n",
       "750251127673729024   every man and woman on this eah is born to lea...   \n",
       "482175176            govmurphy woohoo omg i love this so much egolb...   \n",
       "...                                                                ...   \n",
       "1120598108482736128  saluting the warrior spirit of cancer esconpro...   \n",
       "15611093             adamsinger until you live there and realize th...   \n",
       "402622605            ଏକ ବୟସ ସମୟ ଏକ ବୟସ ସମୟ ଏକ ଆଇନ କ ଣ କଣ ଏକ ଆଇନ କ ଣ...   \n",
       "1243862687198654466  rudogumbo got you sis pmarkhansen yktv rudogum...   \n",
       "2854734842           world energy conservation day december if you ...   \n",
       "\n",
       "                                                       Polarity  \\\n",
       "429437147             (0.12499999999999997, 0.4091666666666667)   \n",
       "507252116             (0.43783068783068785, 0.7134920634920634)   \n",
       "1065961267440033794    (0.3385974025974026, 0.5524675324675324)   \n",
       "750251127673729024     (0.2408936588103255, 0.5157435465768798)   \n",
       "482175176              (0.1299107142857143, 0.4399496336996337)   \n",
       "...                                                         ...   \n",
       "1120598108482736128   (0.17820634920634923, 0.4993174603174603)   \n",
       "15611093              (0.11846193022663612, 0.5541889483065954)   \n",
       "402622605                                           (0.8, 0.75)   \n",
       "1243862687198654466  (0.39112554112554115, 0.47886904761904764)   \n",
       "2854734842            (0.21497425997425998, 0.5580952380952381)   \n",
       "\n",
       "                                                   Subjectivity  \n",
       "429437147             (0.12499999999999997, 0.4091666666666667)  \n",
       "507252116             (0.43783068783068785, 0.7134920634920634)  \n",
       "1065961267440033794    (0.3385974025974026, 0.5524675324675324)  \n",
       "750251127673729024     (0.2408936588103255, 0.5157435465768798)  \n",
       "482175176              (0.1299107142857143, 0.4399496336996337)  \n",
       "...                                                         ...  \n",
       "1120598108482736128   (0.17820634920634923, 0.4993174603174603)  \n",
       "15611093              (0.11846193022663612, 0.5541889483065954)  \n",
       "402622605                                           (0.8, 0.75)  \n",
       "1243862687198654466  (0.39112554112554115, 0.47886904761904764)  \n",
       "2854734842            (0.21497425997425998, 0.5580952380952381)  \n",
       "\n",
       "[335 rows x 3 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Polarity']=df['tweet'].apply(lambda x: TextBlob(x).sentiment)\n",
    "df['Subjectivity']=df['tweet'].apply(lambda x: TextBlob(x).sentiment)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
